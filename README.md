# falcon-lora-finetune
# ğŸ¦… Falcon LoRA - IMDb Sentiment Fine-Tuning

This repository contains the code for fine-tuning the [tiiuae/falcon-rw-1b](https://huggingface.co/tiiuae/falcon-rw-1b) model using the [IMDb movie reviews dataset](https://huggingface.co/datasets/imdb), leveraging the LoRA (Low-Rank Adaptation) method from PEFT for efficient training.

## ğŸ“‚ Project Structure

modelfinetuning/
â”œâ”€â”€ train.py # Fine-tuning script
â”œâ”€â”€ test_lora_inference.py # Inference script using trained adapter
â”œâ”€â”€ pushtohuggingface.ipynb # Notebook to push LoRA adapter to Hugging Face Hub
â”œâ”€â”€ requirements.txt # All required dependencies
â””â”€â”€ README.md # Project overview and instructions



---

## ğŸš€ Model Overview

- **Base Model:** `tiiuae/falcon-rw-1b`
- **Fine-tuning Method:** LoRA via `peft`
- **Dataset:** IMDb (1000 samples for demo)
- **Training Frameworks:** ğŸ¤— Transformers + PEFT
- **Trained On:** Google Colab (T4 GPU)
- **Inference Pipeline:** Text Generation (Sentiment-based completion)

ğŸ§  **Final Model on Hugging Face Hub:**
â¡ï¸ [vishal1d/falcon-lora-imdb](https://huggingface.co/vishal1d/falcon-lora-imdb)

---

## ğŸ“¦ Requirements

Install dependencies using:

pip install -r requirements.txt

## ğŸ‹ï¸â€â™‚ï¸ Training (LoRA)
python train.py
## Inference (with LoRA)
python test_lora_inference.py
## This loads your trained adapter and runs a test prompt:

prompt = "The movie was absolutely wonderful because"

## Output:
Generated Output:
The movie was absolutely wonderful because...


## â˜ï¸ Push to Hugging Face Hub
To upload your adapter to your Hugging Face account:

Login:

from huggingface_hub import notebook_login
notebook_login()

## Run
!python pushtohuggingface.ipynb








